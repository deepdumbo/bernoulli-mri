{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/home/tobias/projects/bernoulli-mri')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.config import get_configuration\n",
    "from src.constraint import ScoreConstrainer\n",
    "from src.dense_rate import DenseRateScheduler\n",
    "from src.optimization import get_mask_handler\n",
    "from src.utils import (\n",
    "    get_temperature,\n",
    "    ifft2c,\n",
    "    plot_heatmap,\n",
    "    min_max_normalize,\n",
    "    MaskLogger\n",
    ")\n",
    "from src.datasets import ACDCDataset, BrainDataset, KneeDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    'file_path': '/data',\n",
    "    'slice_idx': 17,\n",
    "    'coil_idx': None,\n",
    "    'cropping': (256, 256),\n",
    "    'steps': 2500,\n",
    "    'learning_rate': 1e-2,\n",
    "    'bern_samples': 4,\n",
    "    'mask_style': 'f',\n",
    "    'dense_target': 1 / 64,\n",
    "    'dense_start': 0.10,\n",
    "    'dense_end': 0.85,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'log_dir': 'logs/dump',\n",
    "    'log_imgs': 10,\n",
    "}\n",
    "\n",
    "cfg = get_configuration(BASE_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()\n",
    "#loss_func = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "dense_scheduler = DenseRateScheduler(\n",
    "            target=cfg.dense_target,\n",
    "            start_epoch=int(cfg.dense_start * cfg.steps),\n",
    "            stop_epoch=int(cfg.dense_end * cfg.steps),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "num_samples = 64\n",
    "#ds = ACDCDataset('/data/ACDC', train=True)\n",
    "ds = BrainDataset('/data/Task01_BrainTumour', train=True)\n",
    "#ds = KneeDataset('/data/knee_fastmri', train=True)\n",
    "data_loader = DataLoader(ds, batch_size=num_samples, shuffle=True, num_workers=16)\n",
    "\n",
    "def cycle(iterable):\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "            \n",
    "data_iter = iter(cycle(data_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2500 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (256) must match the size of tensor b (320) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 54\u001b[0m\n\u001b[1;32m     49\u001b[0m mask \u001b[38;5;241m=\u001b[39m mask_handler\u001b[38;5;241m.\u001b[39msample_mask(\n\u001b[1;32m     50\u001b[0m     temperature\u001b[38;5;241m=\u001b[39mtemperature, num_samples\u001b[38;5;241m=\u001b[39mcfg\u001b[38;5;241m.\u001b[39mbern_samples \u001b[38;5;241m*\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     51\u001b[0m )\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Compute image with mask\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m img_pred \u001b[38;5;241m=\u001b[39m ifft2c(\u001b[43mimg_k_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.0\u001b[39m)\n\u001b[1;32m     55\u001b[0m img_mag \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(img_pred)\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Compute loss between full and undersampled image\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (256) must match the size of tensor b (320) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "# Create container for masks during training\n",
    "logger = MaskLogger(cfg.log_dir)\n",
    "\n",
    "# Create mask handler that also contains scores\n",
    "mask_handler = get_mask_handler(\n",
    "    name=cfg.mask_style,\n",
    "    height=320,\n",
    "    width=320,\n",
    "    device=cfg.device,\n",
    ")\n",
    "\n",
    "# Initialize optimizer with mask scores\n",
    "optimizer = Adam([mask_handler.get_scores()], lr=cfg.learning_rate)\n",
    "\n",
    "# Create constrainer for projection of scores to dense_rate\n",
    "constrainer = ScoreConstrainer(mask_handler.get_scores())\n",
    "\n",
    "log_recs = []\n",
    "log_masks = []\n",
    "\n",
    "for step in (pbar := tqdm(range(1, cfg.steps + 1))):\n",
    "    \n",
    "    samples = next(data_iter)\n",
    "    img = samples['img']\n",
    "    img_k = samples['k_space']\n",
    "    \n",
    "    img = img.to(cfg.device)\n",
    "    img_k = img_k.to(cfg.device)\n",
    "\n",
    "    img_k_batch = torch.repeat_interleave(img_k, repeats=cfg.bern_samples, dim=0)\n",
    "    img_batch = torch.repeat_interleave(img, repeats=cfg.bern_samples, dim=0)\n",
    "\n",
    "\n",
    "    seg_weight = 50\n",
    "    seg = samples['seg']\n",
    "    seg[seg != 0] = seg_weight\n",
    "    seg[seg == 0] = 1\n",
    "    seg = torch.repeat_interleave(seg, repeats=cfg.bern_samples, dim=0).to(cfg.device)\n",
    "\n",
    "    # Get temperature for categorical \"softness\"\n",
    "    temperature = get_temperature(step, cfg.steps)\n",
    "\n",
    "    # Map scores to valid probability space\n",
    "    dense_rate = dense_scheduler.get_dense_rate()\n",
    "    constrainer.constrain(dense_rate=dense_rate)\n",
    "    dense_scheduler.advance()\n",
    "\n",
    "    # Sample from distribution\n",
    "    mask = mask_handler.sample_mask(\n",
    "        temperature=temperature, num_samples=cfg.bern_samples * img.shape[0]\n",
    "    )\n",
    "\n",
    "    # Compute image with mask\n",
    "    img_pred = ifft2c(img_k_batch * mask + 0.0)\n",
    "    img_mag = torch.abs(img_pred)\n",
    "\n",
    "    # Compute loss between full and undersampled image\n",
    "    loss = loss_func(img_mag, img_batch)\n",
    "\n",
    "    #loss *= seg\n",
    "    #loss = torch.mean(loss)\n",
    "\n",
    "    # Optimize scores\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 20 == 0:\n",
    "        pbar.set_description(\n",
    "            'L: {:.2E} | D: {:.3f}'.format(\n",
    "                float(loss), float(torch.mean(mask_handler.get_scores()))\n",
    "            )\n",
    "        )\n",
    "\n",
    "    num_imgs = cfg.log_imgs\n",
    "    log_interval = 50\n",
    "    \n",
    "    if step == 1 or step % log_interval == 0:\n",
    "        logger.append(probs=mask_handler.get_mask_distribution(),\n",
    "                      step=step, dense_rate=dense_scheduler.get_dense_rate())\n",
    "    \n",
    "    \n",
    "    if num_imgs > 0 and step % (cfg.steps // num_imgs) == 0:\n",
    "        img_rec = torch.abs(img_pred[0])\n",
    "        \n",
    "        img_low_q = torch.quantile(img, 0.01)\n",
    "        img_high_q = torch.quantile(img, 0.99)\n",
    "        \n",
    "        img_rec = min_max_normalize(img_rec, img_low_q, img_high_q)\n",
    "\n",
    "        log_recs.append(img_rec.detach().cpu())\n",
    "        log_masks.append(mask[0].detach().cpu())\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "logger.write()\n",
    "\n",
    "# Construct training progress grid\n",
    "os.makedirs(cfg.log_dir, exist_ok=True)\n",
    "img_org = min_max_normalize(img[0], img_low_q, img_high_q)\n",
    "log_recs.append(img_org.cpu())\n",
    "log_masks.append(torch.zeros_like(img[0]).cpu())\n",
    "\n",
    "save_image(\n",
    "    log_recs + log_masks,\n",
    "    fp=cfg.log_dir + '/progress.png',\n",
    "    nrow=len(log_recs),\n",
    ")\n",
    "\n",
    "# Construct heatmap\n",
    "plot_heatmap(\n",
    "    mask_handler.get_mask_distribution(),\n",
    "    save_path=cfg.log_dir + '/heatmap.png',\n",
    ")\n",
    "\n",
    "# Construct histogram of scores\n",
    "plt.hist(mask_handler.get_scores().detach().cpu().flatten(), bins=20)\n",
    "plt.savefig(cfg.log_dir + '/histogram.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
