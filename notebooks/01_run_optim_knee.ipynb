{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00e88148",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.chdir('/data/core-rad/tobweber/bernoulli-mri')\n",
    "\n",
    "import torch\n",
    "from src.run import run_dataset_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470c739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'dataset': 'knee',\n",
    "    'dataset_root': '/data/core-rad/data',\n",
    "    'batch_size': 256,\n",
    "    'steps': 10000,\n",
    "    'use_seg': False,\n",
    "    'learning_rate': 5e-3,\n",
    "    'bern_samples': 1,\n",
    "    'mask_style': 'h',\n",
    "    'num_workers': 16,\n",
    "    'dense_target': 1 / 8,\n",
    "    'dense_start': 0.10,\n",
    "    'dense_end': 0.90,\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'log_dir': 'logs/acdc_ensemble_8',\n",
    "    'log_imgs': 10,\n",
    "    'log_interval': 100,\n",
    "    'seed': None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03e7e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "L: 6.75E-11 | D: 1.000:  10%|██▉                          | 999/10000 [03:29<31:24,  4.78it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "quantile() input tensor is too large",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 9\u001B[0m\n\u001B[1;32m      6\u001B[0m cfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdense_target\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m/\u001B[39m acc_fac\n\u001B[1;32m      7\u001B[0m cfg[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlog_dir\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogs\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mknee_ensemble_1d_\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(acc_fac) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_m\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(i))\n\u001B[0;32m----> 9\u001B[0m \u001B[43mrun_dataset_optim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/data/core-rad/tobweber/bernoulli-mri/src/run.py:149\u001B[0m, in \u001B[0;36mrun_dataset_optim\u001B[0;34m(cfg, loss_func)\u001B[0m\n\u001B[1;32m    146\u001B[0m     img_rec \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mabs(img_pred[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    147\u001B[0m     log_masks\u001B[38;5;241m.\u001B[39mappend(mask[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdetach()\u001B[38;5;241m.\u001B[39mcpu())\n\u001B[0;32m--> 149\u001B[0m img_low_q \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquantile\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.01\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m img_high_q \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mquantile(img, \u001B[38;5;241m0.99\u001B[39m)\n\u001B[1;32m    151\u001B[0m img_rec \u001B[38;5;241m=\u001B[39m min_max_normalize(img_rec, img_low_q, img_high_q)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: quantile() input tensor is too large"
     ]
    }
   ],
   "source": [
    "num_members = 10\n",
    "acc_facs = [4, 8, 16, 32]\n",
    "\n",
    "for acc_fac in acc_facs:\n",
    "    for i in range(1, 1 + num_members):\n",
    "        cfg['dense_target'] = 1 / acc_fac\n",
    "        cfg['log_dir'] = os.path.join('logs', 'knee_ensemble_1d_' + str(acc_fac) + '_m' + str(i))\n",
    "            \n",
    "        run_dataset_optim(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5578fce2",
   "metadata": {},
   "source": [
    "# Compute Expected Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e402ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from src.utils import get_top_k_mask\n",
    "\n",
    "\n",
    "for acc_fac in acc_facs:\n",
    "    path_stem = f'logs/knee_ensemble_1d_{acc_fac}_m'\n",
    "\n",
    "    paths = [path_stem + str(i) + '/results.pt' for i in range(1, num_members + 1)]\n",
    "    scores = [torch.load(f)['scores'][-1].cuda() for f in paths]\n",
    "\n",
    "    scores_sum = torch.sum(torch.cat(scores), dim=(0,1))\n",
    "\n",
    "    mask = get_top_k_mask(scores_sum, acc_fac)\n",
    "    plt.imshow(mask.cpu(), cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "    new_path = f'logs/knee_ensemble_1d_{acc_fac}'\n",
    "    os.makedirs(new_path, exist_ok=True)\n",
    "    torch.save({\n",
    "        'scores': [scores_sum.cpu()]\n",
    "    }, os.path.join(new_path, 'results.pt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
